<!DOCTYPE html>
<html>
<head>
    <title>Vincent Sitzmann</title>

    <!-- Meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom Styles -->
    <style>
          body {
            font-family: Roboto, 'sans-serif';
            font-size: 16px;
            background-color: #FFFFFF;
            color: #4F6071;
          }
          h1 {
              font-weight: 300;
              font-size: 2rem;
          }
          #header {
            background-color: #f4f4f4;
            /*background-color: #FFFFFF;*/
            display: flex;
            align-items: flex-end;
            padding-top:60px;
            padding-bottom:60px;
          }
          #footer {
            background-color: #FFFFFF;
            padding:60px;
          }
          #portrait {
            border: 3px solid white;
          }
          #header-text {
            margin-top: 60px;
            margin-left: 220px;
          }
          #header-text-name {
            font-size: 40px;
          }
          #header-text-title {
              font-size: 17px;
          }
          #header-text-affiliation {
              font-size: 17px;
              margin-top: 10px;
          }
          #header-text-email {
            margin-top: 10px;
            font-size: 17px;
            font-style: italic;
          }
          .header-text-desc {
            font-size: 20px;
          }
          .vspace-top {
            margin-top: 30px;
          }
          .vspace-top-news {
              margin-top: 15px;
          }
          .paper-image {
            width: 150px;
          }
          .news-date {
              font-weight: bold;
          }
          .paper-title {
            font-weight: bold;
          }
          .paper-authors {
            font-style: italic;
          }
    </style>
</head>

<body>
    <div id='header'>
        <div class='container'>
            <div class='row'>
                <div class="col-sm-3 offset-sm-1">
                    <img src='imgs/portrait.jpeg' class='img-fluid' id='portrait'>
                </div>

                <div class="col">
                  <div id='header-text-name'>
                      Vincent Sitzmann
                  </div>
                    <div id='header-text-title'>
                        Assistant Professor </br>
                        Principal investigator, <a href="https://www.scenerepresentations.org">Scene Representation Group</a>
                    </div>
                    <div id='header-text-affiliation'>
                        MIT Department of <a href="https://www.eecs.mit.edu/">Electrical Engineering & Computer Science</a></br>
                        <a href="https://www.csail.mit.edu/">Computer Science and Artificial Intelligence Laboratory</a> (CSAIL)
                    </div>
                  <div id='header-text-email'>
                        sitzmann (at) mit (dot) edu
                  </div>
                  <div>
                    <a href="https://github.com/vsitzmann">[GitHub]</a>
                    <a href="https://scholar.google.com/citations?user=X44QVV4AAAAJ&hl=en&oi=ao">[Google Scholar]</a>
                    <a href="https://linkedin.com/in/vincentsitzmann">[LinkedIn]</a>
                    <a href="https://twitter.com/vincesitzmann">[Twitter]</a>
                    <a href="https://sigmoid.social/@vsitzmann">[Mastodon]</a>
                    <a href="docs/cv_vincent_sitzmann.pdf">[Download CV]</a>
                  </div>

                </div>
            </div>
        </div>
    </div>


    <div class='container'>
        <div class='row vspace-top'>
            <div class='col offset-sm-1'>
                <h1>Bio</h1>
                <p>
                    I am an Assistant Professor at MIT EECS, where I am leading the
                    <a href="https://www.scenerepresentations.org">Scene Representation Group</a>. Previously, I did my Ph.D. at Stanford University
                    as well as a Postdoc at MIT CSAIL.
                    My research interest lies in neural scene representations - the way neural networks learn to represent information on our world.
                    My goal is to allow independent agents to reason about our world given visual observations,
                    such as inferring a complete model of a scene with information on geometry, material, lighting etc.
                    from only few observations, a task that is simple for humans, but currently impossible for AI.
                </p>

<!--                <h1>Looking for graduate students!</h1>-->
<!--                <p>-->
<!--                    I am looking for graduate students to join my lab at MIT in July 2023. If you want to push what's-->
<!--                    possible with neural scene representations, inverse graphics and neural rendering-->
<!--                    and apply them to problems across computer vision, graphics, and robotics, please apply-->
<!--                    <a href="https://gradapply.mit.edu/eecs/apply/login/">here</a> - -->
<!--                    deadline is December 15th 2022!-->
<!--                </p>-->

<!--                <div class='vspace-top'>-->
<!--                    <h1>News</h1>-->
<!--                </div>-->

<!--                &lt;!&ndash;- List of news -&#45;&#45;!>-->
<!--                <div class='row vspace-top-news'>-->
<!--                    <div class="col-sm-2 news-date">-->
<!--                        March 2022-->
<!--                    </div>-->
<!--                    <div class="col">-->
<!--                        My group website is now online - check i to -->
<!--                    </div>-->
<!--                    -->
<!--                    <div class="col-sm-2 news-date">-->
<!--                        June 2021-->
<!--                    </div>-->
<!--                    <div class="col">-->
<!--                        I am thrilled to announce that I will be joining MIT as tenure-track assistant professor in July-->
<!--                        2022! My lab will investigate neural scene representations, inverse graphics,-->
<!--                        neural rendering, and their applications in vision, graphics, robotics, and AI.-->
<!--                    </div>-->
<!--                </div>-->

<!--                <div class='row vspace-top-news'>-->
<!--                    <div class="col-sm-2 news-date">-->
<!--                        June 2021-->
<!--                    </div>-->
<!--                    <div class="col">-->
<!--                        I have created a slideshare account and will start uploading slides for some of my presentations-->
<!--                        / talks / courses, starting with the slides for the introduction to novel view synthesis at SIGGRAPH-->
<!--                        2021. Feel free to re-use them - I only ask that you keep some form of acknowledgement :) Find them-->
<!--                        <a href="https://www.slideshare.net/VincentSitzmann/">here.</a>-->
<!--                    </div>-->
<!--                </div>-->

<!--                <div class='row vspace-top-news'>-->
<!--                    <div class="col-sm-2 news-date">-->
<!--                        January 2021-->
<!--                    </div>-->
<!--                    <div class="col">-->
<!--		    	I published a <a href="https://github.com/vsitzmann/awesome-implicit-representations">-->
<!--                        reading list on neural implicit representations</a> on github that I give students to get started in this area, inspired by the awesome-computer-vision list with extra commentary &amp; notes. Check it out!-->
<!--                    </div>-->
<!--                </div>-->

<!--                <div class='row vspace-top-news'>-->
<!--                    <div class="col-sm-2 news-date">-->
<!--                        January 2021-->
<!--                    </div>-->
<!--                    <div class="col">-->
<!--		    I am now serving as an academic advisor to <a href="https://preferred.jp/en/news/pr20210113/">Preferred Networks, Inc</a>!-->
<!--                    </div>-->
<!--                </div>-->

<!--                <div class='row vspace-top-news'>-->
<!--                    <div class="col-sm-2 news-date">-->
<!--                        June 2020-->
<!--                    </div>-->
<!--                    <div class="col">-->
<!--                        I just graduated Stanford with my <a href="docs/self_supervised_scene_rep_learning_vsitzmann.pdf">-->
<!--                        thesis on Self-supervised Scene Representation Learning</a>. There's a few interesting thoughts in there - -->
<!--                        especially check out the introduction and conclusion!-->
<!--                    </div>-->
<!--                </div>-->

<!--                <div class='row vspace-top-news'>-->
<!--                    <div class="col-sm-2 news-date">-->
<!--                        March 2020-->
<!--                    </div>-->
<!--                    <div class="col">-->
<!--                        Our CVPR tutorial on Neural Rendering is on youtube, free to watch for everyone!-->
<!--                        Here's the <a href="https://www.youtube.com/watch?v=LCTYRqW-ne8">link to the morning session</a> - -->
<!--                        at 2:20:00, I'm giving an overview over Novel View Synthesis.-->
<!--                        Here's the <a href="https://www.youtube.com/watch?v=JlyGNvbGKB8">link to the afternoon session</a>.-->
<!--                    </div>-->
<!--                </div>-->

<!--                <div class='row vspace-top-news'>-->
<!--                    <div class="col-sm-2 news-date">-->
<!--                        November 2019-->
<!--                    </div>-->

<!--                    <div class="col">-->
<!--		    	Our paper "Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations" wins an honorable mention for "Outstanding New Directions" at NeurIPS 2019! Watch my talk <a href="https://slideslive.com/38921749/track-1-session-3">here</a>.-->
<!--                    </div>-->
<!--                </div>-->


<!--                <div class='row vspace-top-news'>-->
<!--                    <div class="col-sm-2 news-date">-->
<!--                        May 2019-->
<!--                    </div>-->

<!--                    <div class="col">-->
<!--                        I will join Prof. Noah Snavely's group at the Google NYC office over the summer and continue working-->
<!--                        on  deep learning for scene understanding and novel view synthesis.-->
<!--                    </div>-->
<!--                </div>-->


                <div class='vspace-top'>
                    <h1>Publications</h1>
                </div>

                <!--- List of publications ---!>
                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="imgs/diffusion_teaser.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Diffusion with Forward Models: Solving Stochastic Inverse Problems Without Direct Supervision
                        </div>
                        <div class='paper-desc'>
                            arXiv 2023
                        </div>
                        <div class='paper-authors'>
                            Ayush Tewari*, Tianwei Yin*, George Cazenavette, Joshua B. Tenenbaum, Fredo Durand, William T. Freeman, <u>Vincent Sitzmann</u>
                        </div>
                        <div>
                            <a href="https://diffusion-with-forward-models.github.io/">[Project page]</a>
                            <a href="https://diffusion-with-forward-models.github.io/diffusion-forward-paper.pdf">[Paper]</a>
                        </div>
                    </div>
                </div>


                <!--- next ---!>
                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="imgs/flowcam_teaser.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                             FlowCam: Training Generalizable 3D Radiance Fields without Camera Poses via Pixel-Aligned Scene Flow
                        </div>
                        <div class='paper-desc'>
                            arXiv 2023
                        </div>
                        <div class='paper-authors'>
                            Cameron Smith, Yilun Du, Ayush Tewari, Vincent Sitzmann
                        </div>
                        <div>
                            <a href="https://cameronosmith.github.io/flowcam/">[Project page]</a>
                            <a href="https://arxiv.org/abs/2306.00180">[Paper]</a>
                            <a href="https://github.com/cameronosmith/FlowCam">[Code]</a>
                        </div>
                    </div>
                </div>


                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="imgs/stereo-view-synthesis-teaser.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Learning to Render Novel Views from Wide-Baseline Stereo Pairs
                        </div>
                        <div class='paper-desc'>
                            CVPR 2023
                        </div>
                        <div class='paper-authors'>
                            Yilun Du, Cameron Smith, Ayush Tewari†, Vincent Sitzmann†
                        </div>
                        <div>
                            <a href="https://yilundu.github.io/wide_baseline/">[Project page]</a>
                            <a href="https://arxiv.org/abs/2304.08463">[Paper]</a>
                            <a href="https://github.com/yilundu/cross_attention_renderer">[Code]</a>
                            <a href="https://colab.research.google.com/drive/1PeL5oJ_eraLEdzTEVPLBwoM2pyv26WcU?usp=sharing">[Colab]</a>
                        </div>
                    </div>
                </div>


                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="groundplans/thumbnail.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Seeing 3D Objects in a Single Image via Self-Supervised Static-Dynamic Disentanglement
                        </div>
                        <div class='paper-desc'>
                            ICLR 2022
                        </div>
                        <div class='paper-authors'>
                            Prafull Sharma, Ayush Tewari, Yilun Du, Sergey Zakharov, Rares Ambrus, Adrien Gaidon,
                            William T. Freeman, Fredo Durand, Joshua B. Tenenbaum, <u>Vincent Sitzmann</u>
                        </div>
                        <div>
                            <a href="https://prafullsharma.net/see3d/">[Project page]</a>
                            <a href="https://prafullsharma.net/see3d/paper.pdf">[Paper]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="feature-fields/thumbnail.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                             Decomposing NeRF for Editing via Feature Field Distillation
                        </div>
                        <div class='paper-desc'>
                            NeurIPS 2022
                        </div>
                        <div class='paper-authors'>
                            Sosuke Kobayashi, Eiichi Matsumoto, <u>Vincent Sitzmann</u>
                        </div>
                        <div>
                            <a href="https://pfnet-research.github.io/distilled-feature-fields/">[Project page]</a>
                            <a href="https://arxiv.org/abs/2205.15585">[Paper]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="ndfs/thumbnail.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Neural Descriptor Fields: SE(3)-Equivariant Object Representations for Manipulation
                        </div>
                        <div class='paper-desc'>
                            ICRA 2022
                        </div>
                        <div class='paper-authors'>
                            Anthony Simeonov*, Yilun Du*, Andrea Tagliasacchi, Alberto Rodriguez, Pulkit Agrawal†, <u>Vincent Sitzmann</u>†
                        </div>
                        <div>
                            <a href="https://yilundu.github.io/ndf/">[Project page]</a>
                            <a href="https://arxiv.org/abs/2112.05124">[Paper]</a>
                            <a href="https://github.com/anthonysimeonov/ndf_robot">[Code]</a>
                            <a href="https://colab.research.google.com/drive/16bFIFq_E8mnAVwZ_V2qQiKp4x4D0n1sG?usp=sharing">[Colab]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="imgs/gem_thumbnail.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Learning Signal-Agnostic Manifolds of Neural Fields
                        </div>
                        <div class='paper-desc'>
                            NeurIPS 2021
                        </div>
                        <div class='paper-authors'>
                            Yilun Du, Katherine M. Collins, Joshua Tenenbaum, <u>Vincent Sitzmann</u>
                        </div>
                        <div>
                            <a href="https://yilundu.github.io/gem/">[Project page]</a>
                            <a href="https://arxiv.org/abs/2111.06387">[Paper]</a>
                            <a href="https://github.com/yilundu/gem">[Code]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="lfns/img/rooms_360_compressed.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering
                        </div>
                        <div class='paper-desc'>
                            NeurIPS 2021 (Spotlight)
                        </div>
                        <div class='paper-authors'>
                            <u>Vincent Sitzmann</u>*, Semon Rezchikov*, William T. Freeman, Joshua B. Tenenbaum, Frédo Durand
                        </div>
                        <div>
                            <a href="https://vsitzmann.github.io/lfns">[Project page]</a>
                            <a href=" http://arxiv.org/abs/2106.02634">[Paper]</a>
                            <a href="https://github.com/vsitzmann/light-field-networks">[Code]</a>
<!--                            <a href="https://colab.research.google.com/github/vsitzmann/siren/blob/master/explore_siren.ipynb">[Colab]</a>-->
                        </div>
                    </div>
                </div>

<!--                <div class='row vspace-top'>-->
<!--                    <div class="col-sm-3">-->
<!--                        <img src='imgs/deep_medial_fields.png' class='img-fluid'>-->
<!--                    </div>-->

<!--                    <div class="col">-->
<!--                        <div class='paper-title'>-->
<!--                            Deep Medial Fields-->
<!--                        </div>-->
<!--                        <div class='paper-desc'>-->
<!--                            arXiv-->
<!--                        </div>-->
<!--                        <div class='paper-authors'>-->
<!--                            Daniel Rebain, Ke Li, <u>Vincent Sitzmann</u>, Soroosh Yazdani, Kwang Moo Yi, Andrea Tagliasacchi-->
<!--                        </div>-->
<!--                        <div>-->
<!--                            <a href="https://arxiv.org/abs/2106.03804">[Paper]</a>-->
<!--                        </div>-->
<!--                    </div>-->
<!--                </div>-->

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="siren/img/poisson_convergence_15s_label.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Implicit Neural Representations with Periodic Activation Functions
                        </div>
                        <div class='paper-desc'>
			    NeurIPS 2020 (Oral)
                        </div>
                        <div class='paper-authors'>
                            <u>Vincent Sitzmann</u>*, Julien N. P. Martel*, Alexander W. Bergman, David B. Lindell, Gordon Wetzstein
                        </div>
                        <div>
                            <a href="https://vsitzmann.github.io/siren">[Project page]</a>
                            <a href="https://arxiv.org/abs/2006.09661">[Paper]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="metasdf/img/metasdf_steps_comp.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            MetaSDF: Meta-learning Signed Distance Functions
                        </div>
                        <div class='paper-desc'>
                            NeurIPS 2020
                        </div>
                        <div class='paper-authors'>
                            <u>Vincent Sitzmann</u>*, Eric R. Chan*, Richard Tucker, Noah Snavely, Gordon Wetzstein
                        </div>
                        <div>
                            <a href="https://vsitzmann.github.io/metasdf">[Project page]</a>
                            <a href="https://github.com/vsitzmann/metasdf">[Code]</a>
                            <a href="https://arxiv.org/abs/2006.09662">[Paper]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/star_img.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
			    State of the Art on Neural Rendering
                        </div>
                        <div class='paper-desc'>
				Computer Graphics Forum 2020 - EG 2020 (STAR Report)
                        </div>
                        <div class='paper-authors'>
                            Ayush Tewari*, Ohad Fried*, Justus Thies*, <u>Vincent Sitzmann*</u>, Stephen Lombardi, Kalyan Sunkavalli, Ricardo Martin-Brualla, Tomas Simon, Jason Saragih, Matthias Nießner, Rohit Pandey, Sean Fanello, Gordon Wetzstein, Jun-Yan Zhu, Christian Theobalt, Maneesh Agrawala, Eli Shechtman, Dan B Goldman, Michael Zollhöfer
                        </div>
                        <div>
                            <a href="https://arxiv.org/pdf/2004.03805.pdf">[Paper]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/srn_seg_repimage.jpg' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
		            Inferring Semantic Information with 3D Neural Scene Representations
                        </div>
                        <div class='paper-desc'>
				3DV
                        </div>
                        <div class='paper-authors'>
                            Amit Kohli*, <u>Vincent Sitzmann*</u>, Gordon Wetzstein
                        </div>
                        <div>
                            <a href="https://www.computationalimaging.org/publications/semantic-srn/">[Project page]</a>
                            <a href="https://arxiv.org/pdf/2003.12673.pdf">[Preprint]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/SRNs.gif' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations
                        </div>
                        <div class='paper-desc'>
			    NeurIPS 2019 (Oral, <b>Honorable Mention "Outstanding New Directions"</b>)
                        </div>
                        <div class='paper-authors'>
                            <u>Vincent Sitzmann</u>, Michael Zollhöfer, Gordon Wetzstein
                        </div>
                        <div>
                            <a href="http://vsitzmann.github.io/srns/">[Project page]</a>
                            <a href="http://arxiv.org/abs/1906.01618">[Preprint]</a>
			    <a href="https://github.com/vsitzmann/scene-representation-networks">[Code]</a>
                        </div>
                    </div>
                </div>


                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/deepvoxels.png' class='img-fluid'>
                    </div>

                    <div class="col">
                      <div class='paper-title'>
                          DeepVoxels: Learning Persistent 3D Feature Embeddings
                      </div>
                      <div class='paper-desc'>
		      CVPR 2019 (Oral)
                      </div>
                      <div class='paper-authors'>
                      <u>Vincent Sitzmann</u>, Justus Thies, Felix Heide, Matthias Nießner, Gordon Wetzstein, Michael Zollhöfer
                      </div>
                      <div>
                         <a href="http://vsitzmann.github.io/deepvoxels/">[Project page]</a>
                         <a href="https://arxiv.org/abs/1812.01024">[Paper]</a>
                         <a href="https://github.com/vsitzmann/deepvoxels">[Code]</a>
                      </div>
                    </div>
                </div>


                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/onn_thumbnail.jpg' class='img-fluid'>
                    </div>

                    <div class="col">
                      <div class='paper-title'>
                          Hybrid optical-electronic convolutional neural networks with optimized diffractive optics for image classification
                      </div>
                      <div class='paper-desc'>
                        Scientific Reports
                      </div>
                      <div class='paper-authors'>
                      Julie Chang, <u>Vincent Sitzmann</u>, Xiong Dun, Wolfgang Heidrich, Gordon Wetzstein
                      </div>
                      <div>
                        <a href="https://www.nature.com/articles/s41598-018-30619-y">[Paper]</a>
                      </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/end-to-end-cam.jpg' class='img-fluid'>
                    </div>

                    <div class="col">
                      <div class='paper-title'>
                          End-to-end Optimization of Optics and Image Processing for Achromatic Extended Depth of Field and Super-resolution Imaging
                      </div>
                      <div class='paper-desc'>
                          SIGGRAPH 2018
                      </div>
                      <div class='paper-authors'>
                          <u>Vincent Sitzmann*</u>, Steven Diamond*, Yifan Peng*, Xiong Dun, Stephen Boyd, Wolfgang Heidrich, Felix Heide, Gordon Wetzstein
                      </div>
                      <div>
                         <a href="https://vsitzmann.github.io/deepoptics/">[Project page]</a>
                         <a href="https://drive.google.com/file/d/1Xums2qyqSGP_z_24HnYpM9gbRm1_uAzY/view?usp=sharing">[Paper]</a>
                         <a href="https://github.com/vsitzmann/deepoptics">[Code]</a>
                      </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/saliency.jpg' class='img-fluid'>
                    </div>

                    <div class="col">
                      <div class='paper-title'>
                        Saliency in VR: How do people explore virtual environments?
                      </div>
                      <div class='paper-desc'>
                        IEEE VR 2018
                      </div>
                      <div class='paper-authors'>
                          <u>Vincent Sitzmann*</u>, Ana Serrano*, Amy Pavel, Maneesh Agrawala, Belen Masia, Diego Gutierrez, Gordon Wetzstein
                      </div>
                      <div>
                        <a href="https://vsitzmann.github.io/vr-saliency">[Project page]</a>
                        <a href="http://ieeexplore.ieee.org/document/8269807/">[Paper]</a>
                        <a href="https://www.github.com/vsitzmann/vr-saliency">[Code]</a>
                      </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/cognitive_events.jpg' class='img-fluid'>
                    </div>

                    <div class="col">
                      <div class='paper-title'>
                          Movie Editing and Cognitive Event Segmentation in Virtual Reality Video
                      </div>
                      <div class='paper-desc'>
                          SIGGRAPH 2017
                      </div>
                      <div class='paper-authors'>
                          Ana Serrano, <u>Vincent Sitzmann</u>, Jaime Ruiz-Borau, Gordon Wetzstein, Diego Gutierrez, Belen Masia
                      </div>
                      <div>
                        <a href="http://webdiis.unizar.es/~aserrano/docs/Serrano_SIGG2017_VR-cine.pdf">[Paper]</a>
                      </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/sickness_prediction.jpg' class='img-fluid'>
                    </div>

                    <div class="col">
                      <div class='paper-title'>
                          Towards a Machine-learning Approach for Sickness Prediction in 360° Stereoscopic Videos
                      </div>
                      <div class='paper-desc'>
                          IEEE VR 2018
                      </div>
                      <div class='paper-authors'>
                          Nitish Padmanaban*, Timon Ruban*, <u>Vincent Sitzmann</u>, Anthony M. Norcia, Gordon Wetzstein
                      </div>
                      <div>
                        <a href="http://ieeexplore.ieee.org/document/8267239/">[Paper]</a>
                      </div>
                    </div>
                </div>
            </div>
        </div>
    </div>


    <div id='footer' class='vspace-top'>
    <div>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="js/bootstrap.min.js"></script>
</body>

</html>
